{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aa7f3ac",
   "metadata": {},
   "source": [
    "# Prepare Calibration Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97165232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.9 ðŸš€ Python-3.12.12 torch-2.5.1+cu121 CPU (13th Gen Intel Core i7-13620H)\n",
      "Model summary (fused): 73 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '../../../runs/detect/yolov8s_rdd2022_2class7/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (21.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.1 opset 13...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.84...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 0.8s, saved as '../../../runs/detect/yolov8s_rdd2022_2class7/weights/best.onnx' (42.7 MB)\n",
      "\n",
      "Export complete (1.1s)\n",
      "Results saved to \u001b[1m/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=../../../runs/detect/yolov8s_rdd2022_2class7/weights/best.onnx imgsz=640 \n",
      "Validate:        yolo val task=detect model=../../../runs/detect/yolov8s_rdd2022_2class7/weights/best.onnx imgsz=640 data=../../../data/rdd2class_yolo/rdd2class.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../../../runs/detect/yolov8s_rdd2022_2class7/weights/best.onnx'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "MODEL_PATH = \"../../../runs/detect/yolov8s_rdd2022_2class7/weights/best.pt\"\n",
    "\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "model.export(\n",
    "    format=\"onnx\",\n",
    "    imgsz=640,\n",
    "    opset=13,\n",
    "    simplify=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddee7222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25600 total images\n",
      "âœ… Copied 250 calibration images to ../../../data/calibration_images\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# ================= CONFIG =================\n",
    "RDD_ROOT = Path(\"../../../data/combined_annotatedv2\")   # adjust path\n",
    "OUT_DIR = Path(\"../../../data/calibration_images\")\n",
    "NUM_IMAGES = 250\n",
    "# =========================================\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Collect all images recursively\n",
    "all_images = list(RDD_ROOT.rglob(\"*.jpg\"))\n",
    "\n",
    "print(f\"Found {len(all_images)} total images\")\n",
    "\n",
    "# Random sample\n",
    "sampled = random.sample(all_images, NUM_IMAGES)\n",
    "\n",
    "# Copy & rename cleanly\n",
    "for i, img_path in enumerate(sampled):\n",
    "    dst = OUT_DIR / f\"calib_{i:04d}.jpg\"\n",
    "    shutil.copy(img_path, dst)\n",
    "\n",
    "print(f\"âœ… Copied {NUM_IMAGES} calibration images to {OUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f8582b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 250\n",
      "Shape: (600, 600, 3)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "imgs = list(Path(\"../../../data/calibration_images\").glob(\"*.jpg\"))\n",
    "print(\"Images:\", len(imgs))\n",
    "\n",
    "img = cv2.imread(str(imgs[0]))\n",
    "print(\"Shape:\", img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "468d809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "CALIB_DIR = Path(\"../../../data/calibration_images\")\n",
    "IMG_SIZE = 640\n",
    "\n",
    "def representative_dataset():\n",
    "    images = sorted(CALIB_DIR.glob(\"*.jpg\"))\n",
    "\n",
    "    for img_path in images:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Resize to model input\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        # Convert to float32 [0,1]\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "\n",
    "        # Add batch dimension\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "\n",
    "        yield [img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02136e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1770440464.214540   17987 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5809 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1770440464.832767   17987 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1770440464.832779   17987 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2026-02-07 10:31:04.834240: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/yolo_tf_savedmodel\n",
      "2026-02-07 10:31:04.845434: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2026-02-07 10:31:04.845449: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/yolo_tf_savedmodel\n",
      "I0000 00:00:1770440464.874284   17987 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
      "2026-02-07 10:31:04.875068: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2026-02-07 10:31:04.924877: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/yolo_tf_savedmodel\n",
      "2026-02-07 10:31:04.949492: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 115259 microseconds.\n",
      "2026-02-07 10:31:05.035727: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2026-02-07 10:31:05.452961: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:4061] Estimated count of arithmetic ops: 30.201 G  ops, equivalently 15.101 G  MACs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… INT8 TFLite model saved as: /home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best_int8.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n",
      "2026-02-07 10:35:22.166049: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:4061] Estimated count of arithmetic ops: 30.201 G  ops, equivalently 15.101 G  MACs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "SAVED_MODEL_DIR = \"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/yolo_tf_savedmodel\"\n",
    "OUTPUT_TFLITE = \"/home/saber/GitHub/road_anomaly_detection/runs/detect/yolov8s_rdd2022_2class7/weights/best_int8.tflite\"\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_DIR)\n",
    "\n",
    "# ðŸ”¥ FULL INT8 quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "\n",
    "# Force INT8 everywhere\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(OUTPUT_TFLITE, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"âœ… INT8 TFLite model saved as:\", OUTPUT_TFLITE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb72255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "road_anomaly_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
